{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Activation, Average, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "encoded_y_train = to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) | encoded_y_train shape: (60000, 10)\n",
      "x_test shape : (10000, 28, 28) | y_test shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "shape = 'x_train shape: {} | encoded_y_train shape: {}\\n'\n",
    "shape += 'x_test shape : {} | y_test shape : {}'\n",
    "print(shape.format(x_train.shape, encoded_y_train.shape, x_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv7ts9FO77FOAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f84e8b3c0d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_train[0,:,:],cmap='Greys_r')\n",
    "plt.show()\n",
    "print(y_train[0])\n",
    "print(encoded_y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_and_train(model, num_epochs): \n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(), metrics=['acc']) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1)\n",
    "    tensor_board = TensorBoard(log_dir='logs/', histogram_freq=0, batch_size=32)\n",
    "    history = model.fit(x=x_train, y=encoded_y_train, batch_size=32, epochs=num_epochs, verbose=1, callbacks=[checkpoint, tensor_board], validation_split=0.2)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000,28,28,1)\n",
    "input_shape = x_train[0,:,:,:].shape # 28 by 28\n",
    "print(x_train.shape)\n",
    "model_input = Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_cnn(model_input):\n",
    "    \n",
    "    x = Conv2D(96, kernel_size=(3, 3), activation='relu', padding='same')(model_input)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides = 2)(x)\n",
    "    x = Conv2D(192, (3, 3), activation='relu', padding = 'same')(x)\n",
    "    x = Conv2D(10, (1, 1))(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='first_cnn')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model = first_cnn(model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (60000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b9bdb002a761>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_and_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-7109fe8f0311>\u001b[0m in \u001b[0;36mcompile_and_train\u001b[0;34m(model, num_epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtensor_board\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'logs/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_board\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laeschjs/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1581\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1582\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laeschjs/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1412\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1415\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1416\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/laeschjs/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (60000, 28, 28)"
     ]
    }
   ],
   "source": [
    "_ = compile_and_train(first_model, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
